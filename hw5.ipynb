{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 5: Evaluation metrics\n",
    "### Associated lectures: Lectures 9, 10 \n",
    "\n",
    "**Due date: Tuesday, June 07, 2022 at 18:00**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tests_hw5\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:3}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2022s/blob/master/docs/homework_instructions.md).\n",
    "\n",
    "**You may work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Precision, recall, and f1 score by hand <a name=\"1\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of predicting whether a patient has a disease or not. Below are confusion matrices of two machine learning models: Model A and Model B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model A confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted disease</th>\n",
       "      <th>Predicted no disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual disease</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual no disease</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted disease  Predicted no disease\n",
       "Actual disease                     3                    10\n",
       "Actual no disease                  1                   106"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_A = pd.DataFrame(\n",
    "    [[3, 10],\n",
    "     [1, 106]],\n",
    "    columns=[\"Predicted disease\", \"Predicted no disease\"],\n",
    "    index=[\"Actual disease\", \"Actual no disease\"])\n",
    "\n",
    "cm_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model B confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted disease</th>\n",
       "      <th>Predicted no disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual disease</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual no disease</th>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted disease  Predicted no disease\n",
       "Actual disease                     8                     5\n",
       "Actual no disease                 12                    95"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_B = pd.DataFrame(\n",
    "    [[8, 5],\n",
    "     [12, 95]],\n",
    "    columns=[\"Predicted disease\", \"Predicted no disease\"],\n",
    "    index=[\"Actual disease\", \"Actual no disease\"])\n",
    "\n",
    "cm_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Positive vs. negative class \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Precision, recall, and f1 score depend upon which class is considered \"positive\", that is the thing you wish to find. In the example above, which class is likely to be the \"positive\" class? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class \"has a disease\"  is likely to be the \"positive\" class because the model is trying to predict whether a patient has disease or not. Therefore, it makes sense that class \"has a diseases\" is considered \" as positive\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Accuracy\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Calculate accuracies for Model A and Model B. \n",
    "\n",
    "We'll store all metrics associated with Model A and Model B in the `results_dict` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"A\": {}, \"B\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"accuracy\"] = 109/(3+10+1+106)\n",
    "results_dict[\"B\"][\"accuracy\"] = 103/(8+5+12+95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_2_1(\n",
    "    results_dict[\"A\"][\"accuracy\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_2_2(\n",
    "    results_dict[\"B\"][\"accuracy\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.858333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A         B\n",
       "accuracy  0.908333  0.858333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Which model would you pick? \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Which model would you pick simply based on the accuracy metric? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the accuracy metric, we would choose A because it has a higher accuracy score than B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Precision, recall, f1-score\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Calculate precision, recall, f1-score for Model A and Model B manually, without calling `scikit-learn` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"precision\"] = 3/4\n",
    "results_dict[\"B\"][\"precision\"] = 8/20\n",
    "results_dict[\"A\"][\"recall\"] = 3/13\n",
    "results_dict[\"B\"][\"recall\"] = 8/13\n",
    "results_dict[\"A\"][\"f1\"] = 2*(((3/4)*(3/13))/((3/4)+(3/13)))\n",
    "results_dict[\"B\"][\"f1\"] = 2*(((8/20)*(8/13))/((8/20)+(8/13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_1(\n",
    "    results_dict[\"A\"][\"precision\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_2(\n",
    "    results_dict[\"B\"][\"precision\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_3(\n",
    "    results_dict[\"A\"][\"recall\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_4(\n",
    "    results_dict[\"B\"][\"recall\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_5(\n",
    "    results_dict[\"A\"][\"f1\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_6(\n",
    "    results_dict[\"B\"][\"f1\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the dataframe with all results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.858333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A         B\n",
       "accuracy   0.908333  0.858333\n",
       "precision  0.750000  0.400000\n",
       "recall     0.230769  0.615385\n",
       "f1         0.352941  0.484848"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.858333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A         B\n",
       "accuracy   0.908333  0.858333\n",
       "precision  0.750000  0.400000\n",
       "recall     0.230769  0.615385\n",
       "f1         0.352941  0.484848"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Discussion\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Which metric is more informative in this problem? Why? \n",
    "2. Which model would you pick based on this information? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The confusion matrix is more informative in this problem because we are having imbalanced class. It would be more important to predict people who have diseases than people who don't. In this case, we should be looking at the recall score. Model B has a higher recall score this means it can predict more positive classes than Model A which better serve the purpose of predicting whether a patient has diseases or not.\n",
    "2.  Model B will be a better choice because it has a significant higher recall score than Model A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 1.6 \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Provide 4 to 5 example classification datasets (with links) where accuracy metric would be misleading. Discuss which evaluation metric would be more appropriate for each dataset. You may consider datasets we have used in this course so far. You could also look up datasets on Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy metrics can misleading from datasets that are highly imbalanced. Following the link https://www.kaggle.com/general/46744, it lists a multitude of unbalanced datasets: https://www.kaggle.com/datasets/nih-chest-xrays/sample, https://www.kaggle.com/datasets/uciml/bioassay-datasets, https://archive.ics.uci.edu/ml/datasets/breast+cancer, and https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud (these were double checked and confirmed to be imbalanced). Most of these datasets are classifications for which missing a true result would have negative consequences. As such, a better performance metric would be recall for all datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Classification evaluation metrics using `sklearn` <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "In general, when a dataset is imbalanced, accuracy does not provide the whole story. In class, we looked at credit card fraud dataset which is a classic example of an imbalanced dataset. \n",
    "\n",
    "Another example is customer churn datasets. [Customer churn](https://en.wikipedia.org/wiki/Customer_attrition) refers to the notion of customers leaving a subscription service like Netflix. In this exercise, we will try to predict customer churn in a dataset where most of the customers stay with the service and a small minority cancel their subscription. To start, please download the [Kaggle telecom customer churn dataset](https://www.kaggle.com/becksddf/churn-in-telecoms-dataset). Once you have the data, you should be able to run the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starter code below reads the data CSV as a pandas dataframe and splits it into 70% train and 30% test. \n",
    "\n",
    "Note that `churn` column in the dataset is the target. \"True\" means the customer left the subscription (churned) and \"False\" means they stayed.\n",
    "\n",
    "> Note that for this kind of problem a more appropriate technique is something called survival analysis and we'll be talking about it later in the course. For now, we'll just treat it as a binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>NE</td>\n",
       "      <td>70</td>\n",
       "      <td>415</td>\n",
       "      <td>421-8535</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>213.4</td>\n",
       "      <td>86</td>\n",
       "      <td>36.28</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>17.40</td>\n",
       "      <td>256.6</td>\n",
       "      <td>101</td>\n",
       "      <td>11.55</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>WI</td>\n",
       "      <td>67</td>\n",
       "      <td>510</td>\n",
       "      <td>417-2265</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>134</td>\n",
       "      <td>18.55</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>12.10</td>\n",
       "      <td>91.2</td>\n",
       "      <td>86</td>\n",
       "      <td>4.10</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>NJ</td>\n",
       "      <td>122</td>\n",
       "      <td>415</td>\n",
       "      <td>327-9341</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>34</td>\n",
       "      <td>146.4</td>\n",
       "      <td>104</td>\n",
       "      <td>24.89</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>7.62</td>\n",
       "      <td>220.0</td>\n",
       "      <td>91</td>\n",
       "      <td>9.90</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4.21</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>NV</td>\n",
       "      <td>107</td>\n",
       "      <td>510</td>\n",
       "      <td>419-9688</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>234.1</td>\n",
       "      <td>91</td>\n",
       "      <td>39.80</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>13.86</td>\n",
       "      <td>282.5</td>\n",
       "      <td>100</td>\n",
       "      <td>12.71</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>HI</td>\n",
       "      <td>105</td>\n",
       "      <td>510</td>\n",
       "      <td>364-8128</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>125.4</td>\n",
       "      <td>116</td>\n",
       "      <td>21.32</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>22.23</td>\n",
       "      <td>241.6</td>\n",
       "      <td>104</td>\n",
       "      <td>10.87</td>\n",
       "      <td>11.4</td>\n",
       "      <td>9</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>WY</td>\n",
       "      <td>126</td>\n",
       "      <td>408</td>\n",
       "      <td>339-9798</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>197.6</td>\n",
       "      <td>126</td>\n",
       "      <td>33.59</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>20.95</td>\n",
       "      <td>285.3</td>\n",
       "      <td>104</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>WV</td>\n",
       "      <td>70</td>\n",
       "      <td>510</td>\n",
       "      <td>348-3777</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>143.4</td>\n",
       "      <td>72</td>\n",
       "      <td>24.38</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>14.45</td>\n",
       "      <td>127.9</td>\n",
       "      <td>68</td>\n",
       "      <td>5.76</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>NJ</td>\n",
       "      <td>125</td>\n",
       "      <td>415</td>\n",
       "      <td>406-6400</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>182.3</td>\n",
       "      <td>64</td>\n",
       "      <td>30.99</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>11.88</td>\n",
       "      <td>171.6</td>\n",
       "      <td>96</td>\n",
       "      <td>7.72</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>NE</td>\n",
       "      <td>159</td>\n",
       "      <td>415</td>\n",
       "      <td>362-5111</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>189.1</td>\n",
       "      <td>105</td>\n",
       "      <td>32.15</td>\n",
       "      <td>...</td>\n",
       "      <td>147</td>\n",
       "      <td>20.92</td>\n",
       "      <td>242.0</td>\n",
       "      <td>106</td>\n",
       "      <td>10.89</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>PA</td>\n",
       "      <td>106</td>\n",
       "      <td>408</td>\n",
       "      <td>403-9167</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>133.7</td>\n",
       "      <td>45</td>\n",
       "      <td>22.73</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>15.96</td>\n",
       "      <td>181.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.19</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2333 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  account length  area code phone number international plan  \\\n",
       "1402    NE              70        415     421-8535                 no   \n",
       "1855    WI              67        510     417-2265                 no   \n",
       "633     NJ             122        415     327-9341                 no   \n",
       "1483    NV             107        510     419-9688                yes   \n",
       "2638    HI             105        510     364-8128                 no   \n",
       "...    ...             ...        ...          ...                ...   \n",
       "2154    WY             126        408     339-9798                yes   \n",
       "3089    WV              70        510     348-3777                 no   \n",
       "1766    NJ             125        415     406-6400                 no   \n",
       "1122    NE             159        415     362-5111                 no   \n",
       "1346    PA             106        408     403-9167                yes   \n",
       "\n",
       "     voice mail plan  number vmail messages  total day minutes  \\\n",
       "1402              no                      0              213.4   \n",
       "1855              no                      0              109.1   \n",
       "633              yes                     34              146.4   \n",
       "1483              no                      0              234.1   \n",
       "2638              no                      0              125.4   \n",
       "...              ...                    ...                ...   \n",
       "2154              no                      0              197.6   \n",
       "3089             yes                     30              143.4   \n",
       "1766              no                      0              182.3   \n",
       "1122              no                      0              189.1   \n",
       "1346              no                      0              133.7   \n",
       "\n",
       "      total day calls  total day charge  ...  total eve calls  \\\n",
       "1402               86             36.28  ...               77   \n",
       "1855              134             18.55  ...               76   \n",
       "633               104             24.89  ...              103   \n",
       "1483               91             39.80  ...              105   \n",
       "2638              116             21.32  ...               95   \n",
       "...               ...               ...  ...              ...   \n",
       "2154              126             33.59  ...              112   \n",
       "3089               72             24.38  ...               92   \n",
       "1766               64             30.99  ...              121   \n",
       "1122              105             32.15  ...              147   \n",
       "1346               45             22.73  ...              107   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  \\\n",
       "1402             17.40                256.6                101   \n",
       "1855             12.10                 91.2                 86   \n",
       "633               7.62                220.0                 91   \n",
       "1483             13.86                282.5                100   \n",
       "2638             22.23                241.6                104   \n",
       "...                ...                  ...                ...   \n",
       "2154             20.95                285.3                104   \n",
       "3089             14.45                127.9                 68   \n",
       "1766             11.88                171.6                 96   \n",
       "1122             20.92                242.0                106   \n",
       "1346             15.96                181.9                 89   \n",
       "\n",
       "      total night charge  total intl minutes  total intl calls  \\\n",
       "1402               11.55                 5.7                 4   \n",
       "1855                4.10                10.9                 5   \n",
       "633                 9.90                15.6                 4   \n",
       "1483               12.71                10.0                 3   \n",
       "2638               10.87                11.4                 9   \n",
       "...                  ...                 ...               ...   \n",
       "2154               12.84                12.5                 8   \n",
       "3089                5.76                 9.4                 4   \n",
       "1766                7.72                11.6                 7   \n",
       "1122               10.89                10.4                 5   \n",
       "1346                8.19                10.7                 2   \n",
       "\n",
       "      total intl charge  customer service calls  churn  \n",
       "1402               1.54                       1  False  \n",
       "1855               2.94                       2  False  \n",
       "633                4.21                       2  False  \n",
       "1483               2.70                       1  False  \n",
       "2638               3.08                       2  False  \n",
       "...                 ...                     ...    ...  \n",
       "2154               3.38                       2  False  \n",
       "3089               2.54                       3  False  \n",
       "1766               3.13                       2  False  \n",
       "1122               2.81                       1   True  \n",
       "1346               2.89                       1   True  \n",
       "\n",
       "[2333 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bigml_59c28831336c6604c800002a.csv\", encoding=\"utf-8\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Distribution of target values\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Examine the distribution of target values in the train split. Do you see class imbalance? If yes, do we need to deal with it? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.850407\n",
       "True     0.149593\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"churn\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do have class imbalance in the training split. In terms of dealing with it, we must make considerations in the class weighting and use better metrics than accuracy. This way our models don't plateau and fail to predict beyond the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 2.2 EDA \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Come up with **two** exploratory questions you would like to answer and explore those. Briefly discuss your results in 1-3 sentences.\n",
    "\n",
    "You are welcome to use `pandas_profiling` (see Lecture 10) but you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>100.434634</td>\n",
       "      <td>436.324046</td>\n",
       "      <td>8.028290</td>\n",
       "      <td>179.655679</td>\n",
       "      <td>100.567081</td>\n",
       "      <td>30.542015</td>\n",
       "      <td>201.175782</td>\n",
       "      <td>99.885555</td>\n",
       "      <td>17.100210</td>\n",
       "      <td>201.211745</td>\n",
       "      <td>99.988856</td>\n",
       "      <td>9.054591</td>\n",
       "      <td>10.269567</td>\n",
       "      <td>4.503215</td>\n",
       "      <td>2.773365</td>\n",
       "      <td>1.551650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.642470</td>\n",
       "      <td>41.854200</td>\n",
       "      <td>13.665229</td>\n",
       "      <td>54.546284</td>\n",
       "      <td>20.202414</td>\n",
       "      <td>9.272847</td>\n",
       "      <td>50.449386</td>\n",
       "      <td>19.788878</td>\n",
       "      <td>4.288194</td>\n",
       "      <td>50.888058</td>\n",
       "      <td>19.406455</td>\n",
       "      <td>2.290012</td>\n",
       "      <td>2.777601</td>\n",
       "      <td>2.507555</td>\n",
       "      <td>0.749929</td>\n",
       "      <td>1.328702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.400000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>24.380000</td>\n",
       "      <td>167.300000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>14.220000</td>\n",
       "      <td>166.900000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.510000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>179.200000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>30.460000</td>\n",
       "      <td>202.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>201.600000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.070000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>127.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>216.300000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>36.770000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>20.060000</td>\n",
       "      <td>236.600000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>350.800000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>59.640000</td>\n",
       "      <td>354.200000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>30.110000</td>\n",
       "      <td>377.500000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>16.990000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       account length    area code  number vmail messages  total day minutes  \\\n",
       "count     2333.000000  2333.000000            2333.000000        2333.000000   \n",
       "mean       100.434634   436.324046               8.028290         179.655679   \n",
       "std         39.642470    41.854200              13.665229          54.546284   \n",
       "min          1.000000   408.000000               0.000000           0.000000   \n",
       "25%         73.000000   408.000000               0.000000         143.400000   \n",
       "50%        100.000000   415.000000               0.000000         179.200000   \n",
       "75%        127.000000   415.000000              19.000000         216.300000   \n",
       "max        243.000000   510.000000              51.000000         350.800000   \n",
       "\n",
       "       total day calls  total day charge  total eve minutes  total eve calls  \\\n",
       "count      2333.000000       2333.000000        2333.000000      2333.000000   \n",
       "mean        100.567081         30.542015         201.175782        99.885555   \n",
       "std          20.202414          9.272847          50.449386        19.788878   \n",
       "min           0.000000          0.000000           0.000000         0.000000   \n",
       "25%          87.000000         24.380000         167.300000        87.000000   \n",
       "50%         101.000000         30.460000         202.400000       100.000000   \n",
       "75%         114.000000         36.770000         236.000000       113.000000   \n",
       "max         165.000000         59.640000         354.200000       168.000000   \n",
       "\n",
       "       total eve charge  total night minutes  total night calls  \\\n",
       "count       2333.000000          2333.000000        2333.000000   \n",
       "mean          17.100210           201.211745          99.988856   \n",
       "std            4.288194            50.888058          19.406455   \n",
       "min            0.000000            23.200000          33.000000   \n",
       "25%           14.220000           166.900000          87.000000   \n",
       "50%           17.200000           201.600000         100.000000   \n",
       "75%           20.060000           236.600000         113.000000   \n",
       "max           30.110000           377.500000         164.000000   \n",
       "\n",
       "       total night charge  total intl minutes  total intl calls  \\\n",
       "count         2333.000000         2333.000000       2333.000000   \n",
       "mean             9.054591           10.269567          4.503215   \n",
       "std              2.290012            2.777601          2.507555   \n",
       "min              1.040000            0.000000          0.000000   \n",
       "25%              7.510000            8.500000          3.000000   \n",
       "50%              9.070000           10.400000          4.000000   \n",
       "75%             10.650000           12.100000          6.000000   \n",
       "max             16.990000           20.000000         20.000000   \n",
       "\n",
       "       total intl charge  customer service calls  \n",
       "count        2333.000000             2333.000000  \n",
       "mean            2.773365                1.551650  \n",
       "std             0.749929                1.328702  \n",
       "min             0.000000                0.000000  \n",
       "25%             2.300000                1.000000  \n",
       "50%             2.810000                1.000000  \n",
       "75%             3.270000                2.000000  \n",
       "max             5.400000                9.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2333 entries, 1402 to 1346\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   2333 non-null   object \n",
      " 1   account length          2333 non-null   int64  \n",
      " 2   area code               2333 non-null   int64  \n",
      " 3   phone number            2333 non-null   object \n",
      " 4   international plan      2333 non-null   object \n",
      " 5   voice mail plan         2333 non-null   object \n",
      " 6   number vmail messages   2333 non-null   int64  \n",
      " 7   total day minutes       2333 non-null   float64\n",
      " 8   total day calls         2333 non-null   int64  \n",
      " 9   total day charge        2333 non-null   float64\n",
      " 10  total eve minutes       2333 non-null   float64\n",
      " 11  total eve calls         2333 non-null   int64  \n",
      " 12  total eve charge        2333 non-null   float64\n",
      " 13  total night minutes     2333 non-null   float64\n",
      " 14  total night calls       2333 non-null   int64  \n",
      " 15  total night charge      2333 non-null   float64\n",
      " 16  total intl minutes      2333 non-null   float64\n",
      " 17  total intl calls        2333 non-null   int64  \n",
      " 18  total intl charge       2333 non-null   float64\n",
      " 19  customer service calls  2333 non-null   int64  \n",
      " 20  churn                   2333 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 385.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we need to impute the features? From the above we can see that all columns are dense and have no null/missing values. \n",
    "\n",
    "Do we need to scale the numeric features? Some features can use scaling such as account length, number vmail messages, all total calls count features, and customer service calls. Beyond that, I would be wary of scaling the time-based features as well as the currency-based features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Column transformer \n",
    "rubric={points:10}\n",
    "\n",
    "The code below creates `X_train`, `y_train`, `X_test`, `y_test` for you. \n",
    "In preparation for building a classifier, set up a `ColumnTransformer` that performs whatever feature transformations you deem sensible. This can include dropping features if you think they are not helpful. Remember that by default `ColumnTransformer` will drop any columns that aren't accounted for when it's created.\n",
    "\n",
    "In each case, briefly explain your rationale with 1-2 sentences. You do not need an explanation for every feature, but for every group of features that are being transformed the same way. For example, \"I am doing transformation X to the following categorical features: `a`, `b`, `c` because of reason Y,\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"churn\"])\n",
    "X_test = test_df.drop(columns=[\"churn\"])\n",
    "\n",
    "y_train = train_df[\"churn\"]\n",
    "y_test = test_df[\"churn\"]\n",
    "\n",
    "categorical_features = ['state', 'area code']\n",
    "binary_features = ['international plan', 'voice mail plan']\n",
    "scaled_features = ['account length', 'number vmail messages', 'total day calls', 'total eve calls', 'total night calls', 'total intl calls', 'customer service calls', 'total day minutes', 'total day charge', 'total eve minutes', 'total eve charge', 'total night minutes', 'total night charge', 'total intl minutes', 'total intl charge']\n",
    "drop_features = ['phone number']\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\", sparse=False), categorical_features),\n",
    "    (OneHotEncoder(drop=\"if_binary\", dtype=int), binary_features),\n",
    "    (StandardScaler(), scaled_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am doing one hot encoding the categorical features of state as it is the only multi-class, non-ordinal feature in the data-set. This is just the standard approach to categorical features. I am transforming the plans into binary features as they are either yes or no in the data-set. I am scaling some of the numeric features including both currency and time as unscaled numeric data can affect the convergence for logreg models. I am dropping the remaining features, which is just the target feature, for obvious reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualizing the transformed data \n",
    "rubric={points:4}\n",
    "\n",
    "Fit and transform your `ColumnTransformer` on your training set. Print the first 5 rows of the transformed data as a dataframe (not numpy array). See lecture 10 for code that can get you the new column names after transforming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_AK</th>\n",
       "      <th>state_AL</th>\n",
       "      <th>state_AR</th>\n",
       "      <th>state_AZ</th>\n",
       "      <th>state_CA</th>\n",
       "      <th>state_CO</th>\n",
       "      <th>state_CT</th>\n",
       "      <th>state_DC</th>\n",
       "      <th>state_DE</th>\n",
       "      <th>state_FL</th>\n",
       "      <th>...</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl charge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200722</td>\n",
       "      <td>-0.415269</td>\n",
       "      <td>0.618769</td>\n",
       "      <td>0.618927</td>\n",
       "      <td>0.069871</td>\n",
       "      <td>0.069926</td>\n",
       "      <td>1.088667</td>\n",
       "      <td>1.089926</td>\n",
       "      <td>-1.645501</td>\n",
       "      <td>-1.644994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198158</td>\n",
       "      <td>0.337507</td>\n",
       "      <td>-1.293778</td>\n",
       "      <td>-1.293517</td>\n",
       "      <td>-1.167277</td>\n",
       "      <td>-1.166291</td>\n",
       "      <td>-2.162302</td>\n",
       "      <td>-2.164029</td>\n",
       "      <td>0.227019</td>\n",
       "      <td>0.222249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200722</td>\n",
       "      <td>0.337507</td>\n",
       "      <td>-0.609809</td>\n",
       "      <td>-0.609654</td>\n",
       "      <td>-2.210130</td>\n",
       "      <td>-2.211244</td>\n",
       "      <td>0.369287</td>\n",
       "      <td>0.369252</td>\n",
       "      <td>1.919489</td>\n",
       "      <td>1.916105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.599603</td>\n",
       "      <td>-0.415269</td>\n",
       "      <td>0.998345</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>-0.754894</td>\n",
       "      <td>-0.755774</td>\n",
       "      <td>1.597736</td>\n",
       "      <td>1.596582</td>\n",
       "      <td>-0.097071</td>\n",
       "      <td>-0.097850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.793679</td>\n",
       "      <td>0.337507</td>\n",
       "      <td>-0.994886</td>\n",
       "      <td>-0.994731</td>\n",
       "      <td>1.195994</td>\n",
       "      <td>1.196515</td>\n",
       "      <td>0.793839</td>\n",
       "      <td>0.792921</td>\n",
       "      <td>0.407069</td>\n",
       "      <td>0.408973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state_AK  state_AL  state_AR  state_AZ  state_CA  state_CO  state_CT  \\\n",
       "1402       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1855       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "633        0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1483       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2638       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "      state_DC  state_DE  state_FL  ...  total intl calls  \\\n",
       "1402       0.0       0.0       0.0  ...         -0.200722   \n",
       "1855       0.0       0.0       0.0  ...          0.198158   \n",
       "633        0.0       0.0       0.0  ...         -0.200722   \n",
       "1483       0.0       0.0       0.0  ...         -0.599603   \n",
       "2638       0.0       0.0       0.0  ...          1.793679   \n",
       "\n",
       "      customer service calls  total day minutes  total day charge  \\\n",
       "1402               -0.415269           0.618769          0.618927   \n",
       "1855                0.337507          -1.293778         -1.293517   \n",
       "633                 0.337507          -0.609809         -0.609654   \n",
       "1483               -0.415269           0.998345          0.998611   \n",
       "2638                0.337507          -0.994886         -0.994731   \n",
       "\n",
       "      total eve minutes  total eve charge  total night minutes  \\\n",
       "1402           0.069871          0.069926             1.088667   \n",
       "1855          -1.167277         -1.166291            -2.162302   \n",
       "633           -2.210130         -2.211244             0.369287   \n",
       "1483          -0.754894         -0.755774             1.597736   \n",
       "2638           1.195994          1.196515             0.793839   \n",
       "\n",
       "      total night charge  total intl minutes  total intl charge  \n",
       "1402            1.089926           -1.645501          -1.644994  \n",
       "1855           -2.164029            0.227019           0.222249  \n",
       "633             0.369252            1.919489           1.916105  \n",
       "1483            1.596582           -0.097071          -0.097850  \n",
       "2638            0.792921            0.407069           0.408973  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.fit(X_train)\n",
    "\n",
    "categorical_columns = list(ct.named_transformers_['onehotencoder-1'].get_feature_names_out(categorical_features))\n",
    "\n",
    "X_train_enc = pd.DataFrame(\n",
    "   ct.transform(X_train), index=X_train.index, columns=(categorical_columns + binary_features + scaled_features)\n",
    ")\n",
    "X_train_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 area code feature\n",
    "rubric={points:4}\n",
    "\n",
    "The original dataset had a feature called `area code`. Let's assume we encoded this feature with one-hot encoding.\n",
    "\n",
    "1. The area codes were numbers to begin with. Why do we want to use one-hot encoding on this feature?\n",
    "2. What were the possible values of `area code`? \n",
    "3. What new feature(s) were created to replace `area code`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Because `area codes` are not continuous values but rather are the encoded names of an area. This means it makes more sense to treat them as categorical.\n",
    "2. There are only three area codes: 408, 415, and 510.\n",
    "3. The newly created features are `area code_408`, `area code_415`, and `area code_510`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Dummy classifier\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Create a `DummyClassifier`. Report the following scoring metrics via cross-validation: accuracy, precision, recall, f1-score. Briefly comment on your results, including any *warnings* the code produces (2 sentences max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cm_values(cm):\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "    accuracy = (TP + TN) / (TN + FP + FN + TP)\n",
    "    recall = TP / (TP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    f1_score = (2 * precision * recall) / (precision + recall)\n",
    "    return pd.DataFrame({\"accuracy\": [accuracy], \"recall\": [recall], \"precision\": [precision], \"f1_score\": [f1_score]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11936\\3575375009.py:6: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision = TP / (TP + FP)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.850407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  recall  precision  f1_score\n",
       "0  0.850407     0.0        NaN       NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "dummy = DummyClassifier()\n",
    "\n",
    "cm = confusion_matrix(y_train, cross_val_predict(dummy, X_train, y_train))\n",
    "\n",
    "get_cm_values(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy was calculated at 85.0407%. For dummy classifiers, it always predicts the most frequent case. As such, positive was never predicted (given how rare it is). This means that `recall` will be 0 (as is shown above), `precision` will be NaN since both true positive and false positive is 0, and `f1_score` will be NaN since it relies on `precision`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Logistic regression\n",
    "rubric={points:8} \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Train and score a logistic regression classifier on the dataset. \n",
    "2. Report the same metrics as in the previous part.\n",
    "3. Are you satisfied with the results? Use your `DummyClassifier` results as a reference point. Discuss in a few sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.855979</td>\n",
       "      <td>0.209169</td>\n",
       "      <td>0.548872</td>\n",
       "      <td>0.302905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy    recall  precision  f1_score\n",
       "0  0.855979  0.209169   0.548872  0.302905"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr = make_pipeline(ct, LogisticRegression())\n",
    "\n",
    "cm = confusion_matrix(y_train, cross_val_predict(pipe_lr, X_train, y_train))\n",
    "\n",
    "get_cm_values(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wouldn't say I am happy with the results. It is true in saying it out performs the dummy model, especially as recall is no longer 0 and precision is defined (and better than guessing). However, it is very clear that the class imbalance is driving the poor performance of the model beyond accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Logistic regression with `class_weight`\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Set the `class_weight` parameter of your logistic regression model to `'balanced'` and report the same metrics as in the previous part. \n",
    "2. Do you prefer this model to the one in the previous part? Discuss your results in a few sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.760823</td>\n",
       "      <td>0.69914</td>\n",
       "      <td>0.350072</td>\n",
       "      <td>0.466539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy   recall  precision  f1_score\n",
       "0  0.760823  0.69914   0.350072  0.466539"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr = make_pipeline(ct, LogisticRegression(class_weight='balanced'))\n",
    "\n",
    "cm = confusion_matrix(y_train, cross_val_predict(pipe_lr, X_train, y_train))\n",
    "\n",
    "get_cm_values(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do prefer this model to the previous model. This model predicts more false positives which means precision suffers but the recall is much better. I prefer having a higher recall as mis-predicting churn has a larger impact when its true as compared to when its false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Hyperparameter optimization\n",
    "rubric={points:10}\n",
    "\n",
    "Now let's tune the hyperparameters of our `LogisticRegression` using `GridSearchCV` to maximize cross-validation f1 score. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Jointly optimize `C` (choose some reasonable values) and `class_weight` (`None` vs. `'balanced'`) with `GridSearchCV` and `scoring=\"f1\"`. \n",
    "2. What values of `C` and `class_weight` are chosen and what is the best cross-validation f1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47873599874436196,\n",
       " {'logisticregression__C': 0.1,\n",
       "  'logisticregression__class_weight': 'balanced'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr = make_pipeline(ct, LogisticRegression())\n",
    "\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
    "    'logisticregression__class_weight': ['None', 'balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV( pipe_lr, param_grid, cv=5, n_jobs=-1, return_train_score=True, scoring='f1')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_score_, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best values of `C` and `class_weight` are $0.1$ and `'balanced'` respectively. This resulted in a f1 score of $0.47873599874436196$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Test results\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks**\n",
    "1. Evaluate the best model on the test set. In particular show each of the following on the test set:  \n",
    "    - Confusion matrix. \n",
    "    - Classification report. \n",
    "    - Precision-recall curve with average precision score.     \n",
    "    - ROC curve with AUC. \n",
    "3. Comment on the results.    \n",
    "\n",
    "> Note that we are not doing it here but in real life, you would also plot confusion matrix, precision-recall curve, and ROC curve on validation data to examine errors and to choose a threshold which works for your operating point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no-churn     0.9544    0.7725    0.8539       866\n",
      "       churn     0.3411    0.7612    0.4711       134\n",
      "\n",
      "    accuracy                         0.7710      1000\n",
      "   macro avg     0.6477    0.7669    0.6625      1000\n",
      "weighted avg     0.8722    0.7710    0.8026      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision of logistic regression: 0.456\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for LogReg: 0.823\n"
     ]
    }
   ],
   "source": [
    "# all code below is from lecture 9\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# confusion matrix\n",
    "pipe_lr = make_pipeline(ct, LogisticRegression(C=0.1, class_weight='balanced'))\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "plt.rc('font', size=18)\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    pipe_lr,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=[\"No churn\", \"churn\"],\n",
    "    values_format=\"d\",\n",
    "    cmap=plt.cm.Blues,\n",
    "    colorbar=False,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_test, pipe_lr.predict(X_test), target_names=[\"no-churn\", \"churn\"], digits=4))\n",
    "\n",
    "# precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, pipe_lr.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "thresholds = np.append(thresholds, 1)\n",
    "\n",
    "df_PR = pd.DataFrame({\"precision\": precision, \"recall\":recall, \"thresholds\":thresholds}).set_index(\"thresholds\")\n",
    "\n",
    "ax = df_PR[['precision', 'recall']].plot();\n",
    "ax.set_title(\"Precision-Recall vs Thresholds\")\n",
    "ax.set_xlabel(\"Thresholds\")\n",
    "ax.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# average precision score\n",
    "ap_lr = average_precision_score(y_test, pipe_lr.predict_proba(X_test)[:, 1])\n",
    "print(f\"Average precision of logistic regression: {ap_lr:.3f}\")\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pipe_lr.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.title(\"ROC Curve with 0.5 Threshold\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "default_threshold = np.argmin(np.abs(thresholds - 0.5))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[default_threshold],\n",
    "    tpr[default_threshold],\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "# AUC\n",
    "roc_lr = roc_auc_score(y_test, pipe_lr.predict_proba(X_test)[:, 1])\n",
    "print(f\"AUC for LogReg: {roc_lr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Regression metrics <a name=\"3\"></a>\n",
    "<hr> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) from `sklearn datasets`. The code below loads the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing_df = fetch_california_housing(as_frame=True).frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Data spitting and exploration \n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (80%) and test (20%) splits. \n",
    "2. Explore the train split. Do you need to apply any transformations on the data? If yes, create a preprocessor with the appropriate transformations. \n",
    "3. Separate `X` and `y` in train and test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(housing_df, test_size=0.2, random_state=123)\n",
    "\n",
    "scaler_features = list(set(train_df.columns) - set(['MedHouseVal']))\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (StandardScaler(), scaler_features)\n",
    ")\n",
    "\n",
    "X_train = train_df.drop(columns=[\"MedHouseVal\"])\n",
    "X_test = test_df.drop(columns=[\"MedHouseVal\"])\n",
    "\n",
    "y_train = train_df[\"MedHouseVal\"]\n",
    "y_test = test_df[\"MedHouseVal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Baseline: DummyRegressor \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out cross-validation using `DummyRegressor` with default scoring. \n",
    "2. What metric is used for scoring by default? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time      0.001989\n",
       "score_time    0.000399\n",
       "test_score   -0.000147\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = DummyRegressor()\n",
    "\n",
    "scores = cross_validate(dummy, X_train, y_train)\n",
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metric for scoring is R^2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Different regressors\n",
    "rubric={points:8}\n",
    "\n",
    "In this exercise, we are going to use [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) model which we haven't looked into yet. At this point you should feel comfortable using models with our usual ML workflow even if you don't know the details. We'll talk about `RandomForestRegressor` later in the course.  \n",
    "\n",
    "The code below defines a custom scorer called `mape_scorer` and creates dictionaries for different regressors (`models`) and different scoring metrics (`score_types_reg`). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Using the `models` and the evaluation metrics `score_types_reg` in the code below, carry out cross-validation with each model, by passing the evaluation metrics to `scoring` argument of `cross_validate`. Use a pipeline with the model as an estimator if you are applying any transformations. \n",
    "2. Show results as a dataframe. \n",
    "3. Interpret the results. How do the models compare to the baseline? Which model seems to be performing well with different metrics? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <th>train_mape_scorer</th>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <th>test_mape_scorer</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>-0.683433</td>\n",
       "      <td>-0.535459</td>\n",
       "      <td>0.005585</td>\n",
       "      <td>-0.531403</td>\n",
       "      <td>31.764474</td>\n",
       "      <td>-0.724132</td>\n",
       "      <td>0.606300</td>\n",
       "      <td>-0.810379</td>\n",
       "      <td>-0.524369</td>\n",
       "      <td>31.981032</td>\n",
       "      <td>0.481743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.077796</td>\n",
       "      <td>-0.262823</td>\n",
       "      <td>-0.334521</td>\n",
       "      <td>6.096028</td>\n",
       "      <td>-0.124945</td>\n",
       "      <td>7.054443</td>\n",
       "      <td>-0.192158</td>\n",
       "      <td>0.972273</td>\n",
       "      <td>-0.512536</td>\n",
       "      <td>-0.036928</td>\n",
       "      <td>18.875746</td>\n",
       "      <td>0.802412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  score_time  test_neg_mean_squared_error  \\\n",
       "0          Ridge    0.003988                    -0.683433   \n",
       "1  Random Forest    0.077796                    -0.262823   \n",
       "\n",
       "   test_neg_mean_absolute_error  fit_time  train_neg_mean_absolute_error  \\\n",
       "0                     -0.535459  0.005585                      -0.531403   \n",
       "1                     -0.334521  6.096028                      -0.124945   \n",
       "\n",
       "   train_mape_scorer  train_neg_root_mean_squared_error  train_r2  \\\n",
       "0          31.764474                          -0.724132  0.606300   \n",
       "1           7.054443                          -0.192158  0.972273   \n",
       "\n",
       "   test_neg_root_mean_squared_error  train_neg_mean_squared_error  \\\n",
       "0                         -0.810379                     -0.524369   \n",
       "1                         -0.512536                     -0.036928   \n",
       "\n",
       "   test_mape_scorer   test_r2  \n",
       "0         31.981032  0.481743  \n",
       "1         18.875746  0.802412  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "# make a scorer function that we can pass into cross-validation\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "score_types_reg = {\n",
    "    \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape_scorer\": make_scorer(mape, greater_is_better=True),\n",
    "}\n",
    "\n",
    "model_data = []\n",
    "for model in models:\n",
    "    series = pd.DataFrame(cross_validate(models[model], X_train, y_train, return_train_score=True, scoring=score_types_reg)).mean()\n",
    "    series = series.reindex(index = ['model'] + list(set(series.index) - set('model')))\n",
    "    series.at['model'] = model\n",
    "    model_data.append(series)\n",
    "pd.DataFrame(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models perform a lot better than the baseline model. The random forest model is the best model as compared across any metric. The only difference is the time taken to fit and score the model. This makes sense as Ridge is a relatively simple model while random forest is an ensemble of decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 3.4 Hyperparameter optimization \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out hyperparameter optimization using `RandomizedSearchCV` and `Ridge` with the following `param_dist`. The `alpha` hyperparameter of `Ridge` controls the fundamental tradeoff. Choose the metric of your choice for hyperparameter optimization. \n",
    "2. Are you getting better scores compared to the default values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-31.969228370191622"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "pipe_r = make_pipeline(ct, Ridge())\n",
    "\n",
    "param_dist = {\"ridge__alpha\": loguniform(1e-3, 1e3)}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe_r, param_distributions=param_dist, n_jobs=-1, n_iter=10, cv=5, random_state=123, scoring=mape_scorer\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negligible, the value here implies we have around $-31.97\\%$ error on average which is a slightly lower magnitude compared to the default values: average error of $31.98\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Test results\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try the best model on the test set.\n",
    "2. Briefly comment on the results. (1 to 2 sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.12532708479531"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf = make_pipeline(ct, RandomForestRegressor())\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "mape(pipe_rf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the results are better than the mean cross validation scores from above. This could imply that the training set is representative of the population and that the model is not over-trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Model interpretation  \n",
    "rubric={points:4}\n",
    "\n",
    "Ridge is a linear model and it learns coefficients associated with each feature during `fit()`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Visualize coefficients learned by the `Ridge` model above as a pandas dataframe with two columns: features and coefficients. If you attempted 3.4, use the `Ridge` model with best hyperparameters. Otherwise use the `Ridge` model with default hyperparameters. \n",
    "2. Increasing which feature values would result in higher housing price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Population</td>\n",
       "      <td>0.835014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MedInc</td>\n",
       "      <td>0.313316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HouseAge</td>\n",
       "      <td>0.116855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AveBedrms</td>\n",
       "      <td>-0.006809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>-0.041685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>-0.277873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AveRooms</td>\n",
       "      <td>-0.840090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AveOccup</td>\n",
       "      <td>-0.874863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features  coefficients\n",
       "4  Population      0.835014\n",
       "0      MedInc      0.313316\n",
       "1    HouseAge      0.116855\n",
       "3   AveBedrms     -0.006809\n",
       "6    Latitude     -0.041685\n",
       "7   Longitude     -0.277873\n",
       "2    AveRooms     -0.840090\n",
       "5    AveOccup     -0.874863"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_r = make_pipeline(ct, Ridge(alpha=random_search.best_params_['ridge__alpha']))\n",
    "\n",
    "pipe_r.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"features\": X_train.columns,\n",
    "        \"coefficients\": pipe_r.named_steps[\"ridge\"].coef_,\n",
    "    }\n",
    ")\n",
    "\n",
    "df.sort_values(\"coefficients\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the block group population would increase the median value of homes in the block the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from â€œ1â€ will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "name": "_merged",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "438px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
